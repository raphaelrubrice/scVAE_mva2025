{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ac98f488",
      "metadata": {
        "id": "ac98f488"
      },
      "source": [
        "# **Data pipeline**\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/raphaelrubrice/scVAE_mva2025/blob/raph/data_pipeline.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bc8ff6f",
      "metadata": {
        "id": "4bc8ff6f"
      },
      "source": [
        "## **Colab setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "720f662f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "720f662f",
        "outputId": "a194c249-89f6-4e26-d924-c248feb336ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'scVAE_mva2025'...\n",
            "remote: Enumerating objects: 287, done.\u001b[K\n",
            "remote: Counting objects: 100% (156/156), done.\u001b[K\n",
            "remote: Compressing objects: 100% (114/114), done.\u001b[K\n",
            "remote: Total 287 (delta 85), reused 90 (delta 42), pack-reused 131 (from 1)\u001b[K\n",
            "Receiving objects: 100% (287/287), 972.15 KiB | 29.46 MiB/s, done.\n",
            "Resolving deltas: 100% (149/149), done.\n",
            "/content/scVAE_mva2025\n",
            "Branch 'raph' set up to track remote branch 'raph' from 'origin'.\n",
            "Switched to a new branch 'raph'\n",
            "\u001b[31mERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/raphaelrubrice/scVAE_mva2025.git\n",
        "%cd scVAE_mva2025\n",
        "!python -m pip install -r requirements.txt\n",
        "!git checkout raph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50702cbf",
      "metadata": {
        "id": "50702cbf"
      },
      "source": [
        "### Test Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "4dbdf34f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dbdf34f",
        "outputId": "2659989f-1f69-4a27-9780-d12ca7800456"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Saving extracted PBMC datasets to: /content/scVAE_mva2025/data_pipeline/data/pbmc_raw\n",
            "\n",
            "⇩ Downloading and extracting to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD34\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CD34: 100%|\u001b[36m██████████\u001b[0m| 38.0M/38.0M [00:02<00:00, 14.5MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Extracted to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD34\n",
            "✓ Finished CD34\n",
            "------------------------------------------------------------\n",
            "⇩ Downloading and extracting to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD19_B\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CD19_B: 100%|\u001b[36m██████████\u001b[0m| 18.0M/18.0M [00:01<00:00, 13.3MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Extracted to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD19_B\n",
            "✓ Finished CD19_B\n",
            "------------------------------------------------------------\n",
            "⇩ Downloading and extracting to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD56_NK\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CD56_NK: 100%|\u001b[36m██████████\u001b[0m| 20.0M/20.0M [00:01<00:00, 10.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Extracted to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD56_NK\n",
            "✓ Finished CD56_NK\n",
            "------------------------------------------------------------\n",
            "⇩ Downloading and extracting to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD4_helper\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CD4_helper: 100%|\u001b[36m██████████\u001b[0m| 21.0M/21.0M [00:01<00:00, 11.6MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Extracted to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD4_helper\n",
            "✓ Finished CD4_helper\n",
            "------------------------------------------------------------\n",
            "⇩ Downloading and extracting to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD4_CD25\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CD4_CD25: 100%|\u001b[36m██████████\u001b[0m| 19.3M/19.3M [00:01<00:00, 10.7MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Extracted to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD4_CD25\n",
            "✓ Finished CD4_CD25\n",
            "------------------------------------------------------------\n",
            "⇩ Downloading and extracting to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD4_CD45RA_CD25neg\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CD4_CD45RA_CD25neg: 100%|\u001b[36m██████████\u001b[0m| 17.6M/17.6M [00:01<00:00, 10.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Extracted to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD4_CD45RA_CD25neg\n",
            "✓ Finished CD4_CD45RA_CD25neg\n",
            "------------------------------------------------------------\n",
            "⇩ Downloading and extracting to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD4_CD45RO\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CD4_CD45RO: 100%|\u001b[36m██████████\u001b[0m| 20.0M/20.0M [00:01<00:00, 13.2MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Extracted to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD4_CD45RO\n",
            "✓ Finished CD4_CD45RO\n",
            "------------------------------------------------------------\n",
            "⇩ Downloading and extracting to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD8\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CD8: 100%|\u001b[36m██████████\u001b[0m| 20.0M/20.0M [00:01<00:00, 10.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Extracted to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD8\n",
            "✓ Finished CD8\n",
            "------------------------------------------------------------\n",
            "⇩ Downloading and extracting to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD8_CD45RA\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CD8_CD45RA: 100%|\u001b[36m██████████\u001b[0m| 20.9M/20.9M [00:01<00:00, 13.1MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✓ Extracted to /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD8_CD45RA\n",
            "✓ Finished CD8_CD45RA\n",
            "------------------------------------------------------------\n",
            "All PBMC datasets ready in: /content/scVAE_mva2025/data_pipeline/data/pbmc_raw\n"
          ]
        }
      ],
      "source": [
        "from data_pipeline.src.downloader import run_downloads\n",
        "\n",
        "run_downloads()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "d0294263",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "d0294263",
        "outputId": "d3feb4fe-e9f6-47b6-9bbe-80ecd1c03e9c"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'scanpy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3933134841.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDATASETS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdata_pipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_anndata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_anndata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfolder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"data_pipeline/data/pbmc_raw/CD4_CD45RO\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/scVAE_mva2025/data_pipeline/src/load_anndata.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpathlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscanpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0manndata\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'scanpy'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "from data_pipeline.src.config import DATASETS\n",
        "from data_pipeline.src.load_anndata import load_anndata\n",
        "from pathlib import Path\n",
        "\n",
        "folder = Path(\"data_pipeline/data/pbmc_raw/CD4_CD45RO\")\n",
        "meta = DATASETS[\"CD4_CD45RO\"]\n",
        "\n",
        "adata = load_anndata(folder, meta)\n",
        "adata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06d168e1",
      "metadata": {
        "id": "06d168e1"
      },
      "outputs": [],
      "source": [
        "from data_pipeline.src.combine import run_combine\n",
        "\n",
        "combined, collection = run_combine(\n",
        "    do_write_shards=True,\n",
        "    write_combined=True,\n",
        "    harmonize_var=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7d438b7",
      "metadata": {
        "id": "e7d438b7"
      },
      "outputs": [],
      "source": [
        "import scanpy as sc\n",
        "adata_combined = sc.read_h5ad(\"data_pipeline/data/pbmc_processed/pbmc_combined.h5ad\")\n",
        "adata_combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f444b0c",
      "metadata": {
        "id": "1f444b0c"
      },
      "outputs": [],
      "source": [
        "from data_pipeline.src.dataloader import build_cv_dataloaders\n",
        "\n",
        "folds, test_loader = build_cv_dataloaders(\n",
        "    shard_dir=\"data_pipeline/data/pbmc_processed/shards\",\n",
        "    label_maps_path=\"data_pipeline/data/pbmc_processed/label_maps.json\",\n",
        "    batch_size=256,\n",
        "    one_hot=True,\n",
        "    pin_m=True\n",
        "    filter_genes=True,\n",
        "    max_genes=5000,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7788f72",
      "metadata": {
        "id": "a7788f72"
      },
      "source": [
        "# **Cross-Validation of architectures**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "012598bf",
      "metadata": {
        "id": "012598bf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from mixture_vae.distributions import NormalDistribution, UniformDistribution, NegativeBinomial"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6f194b3",
      "metadata": {
        "id": "b6f194b3"
      },
      "source": [
        "## **Cross-Validated scVAE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ecca1c0",
      "metadata": {
        "id": "2ecca1c0"
      },
      "outputs": [],
      "source": [
        "from mixture_vae.mvae import MixtureVAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b29b536",
      "metadata": {
        "id": "8b29b536"
      },
      "outputs": [],
      "source": [
        "# Problem setup\n",
        "input_dim = len(KEPT_GENES) # genes\n",
        "hidden_dim = 100 # hidden neurons per layer\n",
        "n_components = 9 # 9 clusters are assumed\n",
        "latent_dim = 100 # dimension latent space\n",
        "n_layers = 2 # number of encoding and decoding layers\n",
        "\n",
        "# Prior on latent: Standard Gaussian in R2\n",
        "mu = torch.zeros((1,latent_dim))\n",
        "std = torch.ones((1,latent_dim))\n",
        "prior_latent = NormalDistribution({\"mu\":mu,\n",
        "                                    \"std\":std})\n",
        "\n",
        "# Prior on input gene counts: NB for each gene\n",
        "p = 0.5 * torch.ones((1,input_dim)) # 50/50 chance of expression\n",
        "r = torch.mean(X, dim=0).reshape(1,-1) # prior = average count in train data\n",
        "prior_input = NegativeBinomial({\"p\":p,\n",
        "                                \"r\":r})\n",
        "\n",
        "# Prior on cluster repartitions (mixture): Assume balanced\n",
        "# cluster classes = Uniform on [0,1]\n",
        "a = torch.zeros((1,n_components))\n",
        "b = torch.ones((1,n_components))\n",
        "prior_categorical = UniformDistribution({\"a\":a,\n",
        "                                          \"b\":b})\n",
        "\n",
        "# Posterior on latent: Gaussian on R2\n",
        "# (here assumed posterior = assumed prior\n",
        "# but it could have been differnet)\n",
        "mu = torch.zeros((1,latent_dim))\n",
        "std = torch.ones((1,latent_dim))\n",
        "posterior_latent = NormalDistribution({\"mu\":mu,\n",
        "                                        \"std\":std})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7b2e5c0",
      "metadata": {
        "id": "e7b2e5c0"
      },
      "outputs": [],
      "source": [
        "cv_scVAE = []\n",
        "for fold in tqdm(list(range(len(folds)))):\n",
        "    print(f\"\\nInstantiating scVAE..\")\n",
        "    scVAE = MixtureVAE(\n",
        "            input_dim=input_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            n_components=n_components,\n",
        "            n_layers=n_layers,\n",
        "            prior_latent=prior_latent,\n",
        "            prior_input=prior_input,\n",
        "            prior_categorical=prior_categorical,\n",
        "            posterior_latent=posterior_latent\n",
        "        )\n",
        "\n",
        "    train_loader, val_loader = folds[fold]\n",
        "\n",
        "    optimizer = torch.optim.Adam(scVAE.parameters(), lr=1e-4)\n",
        "\n",
        "    EPOCHS = 500\n",
        "    BETA_KL = 1.0\n",
        "    WARMUP_BETA = 200\n",
        "    PATIENCE = 20\n",
        "    TOL = 5e-3\n",
        "\n",
        "    scVAE, losses, parts, clusters, all_betas = training_mvae(\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        scVAE,\n",
        "        optimizer,\n",
        "        epochs=EPOCHS,\n",
        "        beta_kl=BETA_KL,\n",
        "        warmup=WARMUP_BETA,\n",
        "        patience=PATIENCE,\n",
        "        tol=TOL,\n",
        "        show_loss_every=10,\n",
        "        model_type=0,\n",
        "        track_clusters=True,\n",
        "    )\n",
        "\n",
        "    cv_scVAE.append(scVAE)\n",
        "    # plot training and validation losses\n",
        "    plot_loss_components(parts[\"train\"],\n",
        "                         parts[\"val\"],\n",
        "                         all_betas,\n",
        "                         title=\"Loss Breakdown\",\n",
        "                         save_path=f\"./scVAE_{fold}_losses.pdf\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7944b0c4",
      "metadata": {
        "id": "7944b0c4"
      },
      "source": [
        "## **Cross-Validated independent Mixture of Mixtures**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c85ad988",
      "metadata": {
        "id": "c85ad988"
      },
      "outputs": [],
      "source": [
        "from mixture_vae.mvae import ind_MoMVAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "203fd11d",
      "metadata": {
        "id": "203fd11d"
      },
      "outputs": [],
      "source": [
        "cv_IndMoM = []\n",
        "for fold in tqdm(list(range(len(folds)))):\n",
        "    print(f\"\\nInstantiating IndMoM..\")\n",
        "    IndMoM = ind_MoMVAE(\n",
        "            PARAMS = [\n",
        "            {\"input_dim\": input_dim,\n",
        "            \"hidden_dim\": hidden_dim,\n",
        "            \"n_components\": n_components,\n",
        "            \"n_layers\": n_layers,\n",
        "            \"prior_latent\": prior_latent,\n",
        "            \"prior_input\": prior_input,\n",
        "            \"prior_categorical\": prior_categorical,\n",
        "            \"posterior_latent\": posterior_latent}\n",
        "            for n_components in [2, 3, 5, 9]]\n",
        "        )\n",
        "\n",
        "    train_loader, val_loader = folds[fold]\n",
        "\n",
        "    optimizer = torch.optim.Adam(IndMoM.parameters(), lr=1e-3)\n",
        "\n",
        "    EPOCHS = 500\n",
        "    BETA_KL = 1.0\n",
        "    WARMUP_BETA = 200\n",
        "    PATIENCE = 20\n",
        "    TOL = 5e-3\n",
        "\n",
        "    IndMoM, losses, parts, clusters, all_betas = training_mvae(\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        IndMoM,\n",
        "        optimizer,\n",
        "        epochs=EPOCHS,\n",
        "        beta_kl=BETA_KL,\n",
        "        warmup=WARMUP_BETA,\n",
        "        patience=PATIENCE,\n",
        "        tol=TOL,\n",
        "        show_loss_every=10,\n",
        "        model_type=1,\n",
        "        track_clusters=True,\n",
        "    )\n",
        "    cv_IndMoM.append(IndMoM)\n",
        "    # plot training and validation losses\n",
        "    plot_loss_components(parts[\"train\"],\n",
        "                         parts[\"val\"],\n",
        "                         all_betas,\n",
        "                         title=\"Loss Breakdown\",\n",
        "                         save_path=f\"./IndMoM_{fold}_losses.pdf\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0accc7a2",
      "metadata": {
        "id": "0accc7a2"
      },
      "source": [
        "## **Cross-Validated Mixture of Mixtures**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69b4e710",
      "metadata": {
        "id": "69b4e710"
      },
      "outputs": [],
      "source": [
        "from mixture_vae.mvae import MoMixVAE\n",
        "from mixture_vae.training import training_momixvae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cae7d4b5",
      "metadata": {
        "id": "cae7d4b5"
      },
      "outputs": [],
      "source": [
        "# Prior on cluster repartitions (mixture): Assume balanced\n",
        "# cluster classes = Uniform on [0,1]\n",
        "# currently we assume the same for all levels\n",
        "all_prior_categorical = []\n",
        "for n_components in hierarchy_components:\n",
        "    a = torch.zeros((1,n_components))\n",
        "    b = torch.ones((1,n_components))\n",
        "    prior_categorical = UniformDistribution({\"a\":a,\n",
        "                                            \"b\":b})\n",
        "    all_prior_categorical.append(prior_categorical)\n",
        "\n",
        "# Posterior on latent: Gaussian on R2\n",
        "# (here assumed posterior = assumed prior\n",
        "# but it could have been differnet)\n",
        "# currently we assume the same for all levels\n",
        "all_posterior_latent = []\n",
        "for n_components in hierarchy_components:\n",
        "    mu = torch.zeros((1,latent_dim))\n",
        "    std = torch.ones((1,latent_dim))\n",
        "    posterior_latent = NormalDistribution({\"mu\":mu,\n",
        "                                        \"std\":std})\n",
        "    all_posterior_latent.append(posterior_latent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b28bc78",
      "metadata": {
        "id": "4b28bc78"
      },
      "outputs": [],
      "source": [
        "cv_MoMix = []\n",
        "for fold in tqdm(list(range(len(folds)))):\n",
        "    print(f\"\\nInstantiating MoMix..\")\n",
        "    MoMix = MoMixVAE(\n",
        "        input_dim=input_dim,\n",
        "        hidden_dim=hidden_dim,\n",
        "        hierarchy_components=hierarchy_components,\n",
        "        n_layers=n_layers,\n",
        "        prior_latent=prior_latent,\n",
        "        prior_input=prior_input,\n",
        "        all_prior_categorical=all_prior_categorical,\n",
        "        all_posterior_latent=all_posterior_latent\n",
        "    )\n",
        "\n",
        "    train_loader, val_loader = folds[fold]\n",
        "\n",
        "    optimizer = torch.optim.Adam(MoMix.parameters(), lr=1e-3)\n",
        "\n",
        "    EPOCHS = 500\n",
        "    BETA_KL = 1.0\n",
        "    WARMUP_BETA = 200\n",
        "    PATIENCE = 20\n",
        "    TOL = 5e-3\n",
        "\n",
        "    MoMix, losses, parts, clusters, all_betas = training_momixvae(\n",
        "        dataloader,\n",
        "        val_dataloader,\n",
        "        model,\n",
        "        optimizer,\n",
        "        epochs=EPOCHS,\n",
        "        beta_kl=BETA_KL,\n",
        "        warmup=WARMUP,\n",
        "        patience=PATIENCE,\n",
        "        tol=TOL,\n",
        "        show_loss_every=10,\n",
        "        track_clusters=True,\n",
        "    )\n",
        "    cv_MoMix.append(MoMix)\n",
        "    # plot training and validation losses\n",
        "    plot_loss_components(parts[\"train\"],\n",
        "                         parts[\"val\"],\n",
        "                         all_betas,\n",
        "                         title=\"Loss Breakdown\",\n",
        "                         save_path=f\"./MoMix_{fold}_losses.pdf\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d18c50",
      "metadata": {
        "id": "e4d18c50"
      },
      "source": [
        "# **Figure 1: Generative and Clustering performances**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7885f36c",
      "metadata": {
        "id": "7885f36c"
      },
      "outputs": [],
      "source": [
        "from mixture_vae.figure1 import plot_figure1\n",
        "\n",
        "cv_dico = {\"$\\mathcal{N}$(0,I)\": [cv_scVAE, cv_IndMoM, cv_MoMix]}\n",
        "\n",
        "plot_figure1(cv_dico, test_loader, save_path=\"./Figure1.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "876e3060",
      "metadata": {
        "id": "876e3060"
      },
      "outputs": [],
      "source": [
        "# from data_pipeline.src.dataloader import build_dataloaders\n",
        "\n",
        "# train_loader, val_loader, test_loader = build_dataloaders(\n",
        "#     shard_dir=\"data_pipeline/data/pbmc_processed/shards\",\n",
        "#     label_maps_path=\"data_pipeline/data/pbmc_processed/label_maps.json\",\n",
        "#     batch_size=512,\n",
        "#     one_hot=True,\n",
        "# )\n",
        "\n",
        "# for i, batch in enumerate(train_loader):\n",
        "#         print(\"Example batch shapes:\")\n",
        "#         print(\"X:\", batch[\"X\"].shape, \"y1:\", batch[\"y1\"].shape, \"y4:\", batch[\"y4\"].shape)\n",
        "#         break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
