{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "ac98f488",
      "metadata": {
        "id": "ac98f488"
      },
      "source": [
        "# **Data pipeline**\n",
        "<a target=\"_blank\" href=\"https://colab.research.google.com/github/raphaelrubrice/scVAE_mva2025/blob/raph/data_pipeline.ipynb\">\n",
        "  <img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4bc8ff6f",
      "metadata": {
        "id": "4bc8ff6f"
      },
      "source": [
        "## **Colab setup**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "720f662f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "720f662f",
        "outputId": "08c40425-33ff-4b68-a8d4-424377b4e8c6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'scVAE_mva2025'...\n",
            "remote: Enumerating objects: 426, done.\u001b[K\n",
            "remote: Counting objects: 100% (107/107), done.\u001b[K\n",
            "remote: Compressing objects: 100% (65/65), done.\u001b[K\n",
            "remote: Total 426 (delta 60), reused 66 (delta 42), pack-reused 319 (from 1)\u001b[K\n",
            "Receiving objects: 100% (426/426), 1.68 MiB | 21.24 MiB/s, done.\n",
            "Resolving deltas: 100% (238/238), done.\n",
            "/content/scVAE_mva2025/scVAE_mva2025\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (0.13.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (2.9.0+cu126)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (4.67.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (2.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (3.15.1)\n",
            "Requirement already satisfied: anndata in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (0.12.6)\n",
            "Requirement already satisfied: scanpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (1.11.5)\n",
            "Requirement already satisfied: scikit-misc in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (0.5.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (1.6.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (1.16.3)\n",
            "Requirement already satisfied: ipykernel in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (6.17.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (2.32.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->-r requirements.txt (line 1)) (2.9.0.post0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (4.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (75.2.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 4)) (3.5.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 6)) (2025.2)\n",
            "Requirement already satisfied: array-api-compat>=1.7.1 in /usr/local/lib/python3.12/dist-packages (from anndata->-r requirements.txt (line 8)) (1.12.0)\n",
            "Requirement already satisfied: legacy-api-wrap in /usr/local/lib/python3.12/dist-packages (from anndata->-r requirements.txt (line 8)) (1.5)\n",
            "Requirement already satisfied: natsort in /usr/local/lib/python3.12/dist-packages (from anndata->-r requirements.txt (line 8)) (8.4.0)\n",
            "Requirement already satisfied: zarr!=3.0.*,>=2.18.7 in /usr/local/lib/python3.12/dist-packages (from anndata->-r requirements.txt (line 8)) (3.1.5)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from scanpy->-r requirements.txt (line 9)) (1.5.2)\n",
            "Requirement already satisfied: numba!=0.62.0rc1,>=0.57.1 in /usr/local/lib/python3.12/dist-packages (from scanpy->-r requirements.txt (line 9)) (0.60.0)\n",
            "Requirement already satisfied: patsy!=1.0.0 in /usr/local/lib/python3.12/dist-packages (from scanpy->-r requirements.txt (line 9)) (1.0.2)\n",
            "Requirement already satisfied: pynndescent>=0.5.13 in /usr/local/lib/python3.12/dist-packages (from scanpy->-r requirements.txt (line 9)) (0.5.13)\n",
            "Requirement already satisfied: session-info2 in /usr/local/lib/python3.12/dist-packages (from scanpy->-r requirements.txt (line 9)) (0.2.3)\n",
            "Requirement already satisfied: statsmodels>=0.14.5 in /usr/local/lib/python3.12/dist-packages (from scanpy->-r requirements.txt (line 9)) (0.14.5)\n",
            "Requirement already satisfied: umap-learn>=0.5.6 in /usr/local/lib/python3.12/dist-packages (from scanpy->-r requirements.txt (line 9)) (0.5.9.post2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 11)) (3.6.0)\n",
            "Requirement already satisfied: debugpy>=1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 13)) (1.8.15)\n",
            "Requirement already satisfied: ipython>=7.23.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 13)) (7.34.0)\n",
            "Requirement already satisfied: jupyter-client>=6.1.12 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 13)) (7.4.9)\n",
            "Requirement already satisfied: matplotlib-inline>=0.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 13)) (0.2.1)\n",
            "Requirement already satisfied: nest-asyncio in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 13)) (1.6.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 13)) (5.9.5)\n",
            "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 13)) (26.2.1)\n",
            "Requirement already satisfied: tornado>=6.1 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 13)) (6.5.1)\n",
            "Requirement already satisfied: traitlets>=5.1.0 in /usr/local/lib/python3.12/dist-packages (from ipykernel->-r requirements.txt (line 13)) (5.7.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->-r requirements.txt (line 14)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->-r requirements.txt (line 14)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->-r requirements.txt (line 14)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->-r requirements.txt (line 14)) (2025.11.12)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 13)) (0.19.2)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 13)) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 13)) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 13)) (3.0.52)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 13)) (2.19.2)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 13)) (0.2.0)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.12/dist-packages (from ipython>=7.23.1->ipykernel->-r requirements.txt (line 13)) (4.9.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 13)) (0.4)\n",
            "Requirement already satisfied: jupyter-core>=4.9.2 in /usr/local/lib/python3.12/dist-packages (from jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 13)) (5.9.1)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.12/dist-packages (from numba!=0.62.0rc1,>=0.57.1->scanpy->-r requirements.txt (line 9)) (0.43.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib->-r requirements.txt (line 1)) (1.17.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 4)) (1.3.0)\n",
            "Requirement already satisfied: donfig>=0.8 in /usr/local/lib/python3.12/dist-packages (from zarr!=3.0.*,>=2.18.7->anndata->-r requirements.txt (line 8)) (0.8.1.post1)\n",
            "Requirement already satisfied: google-crc32c>=1.5 in /usr/local/lib/python3.12/dist-packages (from zarr!=3.0.*,>=2.18.7->anndata->-r requirements.txt (line 8)) (1.7.1)\n",
            "Requirement already satisfied: numcodecs>=0.14 in /usr/local/lib/python3.12/dist-packages (from zarr!=3.0.*,>=2.18.7->anndata->-r requirements.txt (line 8)) (0.16.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch->-r requirements.txt (line 4)) (3.0.3)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from donfig>=0.8->zarr!=3.0.*,>=2.18.7->anndata->-r requirements.txt (line 8)) (6.0.3)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /usr/local/lib/python3.12/dist-packages (from jedi>=0.16->ipython>=7.23.1->ipykernel->-r requirements.txt (line 13)) (0.8.5)\n",
            "Requirement already satisfied: platformdirs>=2.5 in /usr/local/lib/python3.12/dist-packages (from jupyter-core>=4.9.2->jupyter-client>=6.1.12->ipykernel->-r requirements.txt (line 13)) (4.5.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.12/dist-packages (from pexpect>4.3->ipython>=7.23.1->ipykernel->-r requirements.txt (line 13)) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.23.1->ipykernel->-r requirements.txt (line 13)) (0.2.14)\n",
            "Branch 'raph' set up to track remote branch 'raph' from 'origin'.\n",
            "Switched to a new branch 'raph'\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/raphaelrubrice/scVAE_mva2025.git\n",
        "%cd scVAE_mva2025\n",
        "!python -m pip install -r requirements.txt\n",
        "!git checkout raph"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50702cbf",
      "metadata": {
        "id": "50702cbf"
      },
      "source": [
        "### Test Downloads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "4dbdf34f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dbdf34f",
        "outputId": "6e407ad4-ca2c-44e5-8272-b734fdfd60b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Saving extracted PBMC datasets to: /content/scVAE_mva2025/data_pipeline/data/pbmc_raw\n",
            "\n",
            "✓ Already downloaded/extracted: /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD34\n",
            "------------------------------------------------------------\n",
            "✓ Already downloaded/extracted: /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD19_B\n",
            "------------------------------------------------------------\n",
            "✓ Already downloaded/extracted: /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD56_NK\n",
            "------------------------------------------------------------\n",
            "✓ Already downloaded/extracted: /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD4_helper\n",
            "------------------------------------------------------------\n",
            "✓ Already downloaded/extracted: /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD4_CD25\n",
            "------------------------------------------------------------\n",
            "✓ Already downloaded/extracted: /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD4_CD45RA_CD25neg\n",
            "------------------------------------------------------------\n",
            "✓ Already downloaded/extracted: /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD4_CD45RO\n",
            "------------------------------------------------------------\n",
            "✓ Already downloaded/extracted: /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD8\n",
            "------------------------------------------------------------\n",
            "✓ Already downloaded/extracted: /content/scVAE_mva2025/data_pipeline/data/pbmc_raw/CD8_CD45RA\n",
            "------------------------------------------------------------\n",
            "All PBMC datasets ready in: /content/scVAE_mva2025/data_pipeline/data/pbmc_raw\n"
          ]
        }
      ],
      "source": [
        "from data_pipeline.src.downloader import run_downloads\n",
        "\n",
        "run_downloads()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "d0294263",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 339
        },
        "id": "d0294263",
        "outputId": "30a69dac-81b6-44e5-f47c-c0b2f2a8d611"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "Could not locate matrix.mtx below data_pipeline/data/pbmc_raw/CD4_CD45RO",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3933134841.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmeta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDATASETS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CD4_CD45RO\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0madata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_anndata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0madata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/scVAE_mva2025/data_pipeline/src/load_anndata.py\u001b[0m in \u001b[0;36mload_anndata\u001b[0;34m(folder, meta)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# NEW — automatically find the real matrix directory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0mmatrix_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_find_matrix_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Loading 10x data from: {matrix_dir}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/scVAE_mva2025/data_pipeline/src/load_anndata.py\u001b[0m in \u001b[0;36m_find_matrix_dir\u001b[0;34m(folder)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"matrix.mtx\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mPath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mFileNotFoundError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Could not locate matrix.mtx below {folder}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: Could not locate matrix.mtx below data_pipeline/data/pbmc_raw/CD4_CD45RO"
          ]
        }
      ],
      "source": [
        "from data_pipeline.src.config import DATASETS\n",
        "from data_pipeline.src.load_anndata import load_anndata\n",
        "from pathlib import Path\n",
        "\n",
        "folder = Path(\"data_pipeline/data/pbmc_raw/CD4_CD45RO\")\n",
        "meta = DATASETS[\"CD4_CD45RO\"]\n",
        "\n",
        "adata = load_anndata(folder, meta)\n",
        "adata"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "06d168e1",
      "metadata": {
        "id": "06d168e1"
      },
      "outputs": [],
      "source": [
        "from data_pipeline.src.combine import run_combine\n",
        "\n",
        "combined, collection = run_combine(\n",
        "    do_write_shards=True,\n",
        "    write_combined=True,\n",
        "    harmonize_var=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7d438b7",
      "metadata": {
        "id": "e7d438b7"
      },
      "outputs": [],
      "source": [
        "import scanpy as sc\n",
        "adata_combined = sc.read_h5ad(\"data_pipeline/data/pbmc_processed/pbmc_combined.h5ad\")\n",
        "adata_combined"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1f444b0c",
      "metadata": {
        "id": "1f444b0c"
      },
      "outputs": [],
      "source": [
        "from data_pipeline.src.dataloader import build_cv_dataloaders\n",
        "\n",
        "kept_idx, folds, test_loader = build_cv_dataloaders(\n",
        "    shard_dir=\"data_pipeline/data/pbmc_processed/shards\",\n",
        "    label_maps_path=\"data_pipeline/data/pbmc_processed/label_maps.json\",\n",
        "    batch_size=256,\n",
        "    one_hot=True,\n",
        "    pin_m=True\n",
        "    filter_genes=True,\n",
        "    max_genes=5000,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7788f72",
      "metadata": {
        "id": "a7788f72"
      },
      "source": [
        "# **Cross-Validation of architectures**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "012598bf",
      "metadata": {
        "id": "012598bf"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from mixture_vae.distributions import NormalDistribution, UniformDistribution, NegativeBinomial"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6f194b3",
      "metadata": {
        "id": "b6f194b3"
      },
      "source": [
        "## **Cross-Validated scVAE**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2ecca1c0",
      "metadata": {
        "id": "2ecca1c0"
      },
      "outputs": [],
      "source": [
        "from mixture_vae.mvae import MixtureVAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b29b536",
      "metadata": {
        "id": "8b29b536"
      },
      "outputs": [],
      "source": [
        "# Problem setup\n",
        "input_dim = kept_idx # genes\n",
        "hidden_dim = 100 # hidden neurons per layer\n",
        "n_components = 9 # 9 clusters are assumed\n",
        "latent_dim = 100 # dimension latent space\n",
        "n_layers = 2 # number of encoding and decoding layers\n",
        "\n",
        "# Prior on latent: Standard Gaussian in R2\n",
        "mu = torch.zeros((1,latent_dim))\n",
        "std = torch.ones((1,latent_dim))\n",
        "prior_latent = NormalDistribution({\"mu\":mu,\n",
        "                                    \"std\":std})\n",
        "\n",
        "# Prior on input gene counts: NB for each gene\n",
        "p = 0.5 * torch.ones((1,input_dim)) # 50/50 chance of expression\n",
        "r = torch.mean(X, dim=0).reshape(1,-1) # prior = average count in train data\n",
        "prior_input = NegativeBinomial({\"p\":p,\n",
        "                                \"r\":r})\n",
        "\n",
        "# Prior on cluster repartitions (mixture): Assume balanced\n",
        "# cluster classes = Uniform on [0,1]\n",
        "a = torch.zeros((1,n_components))\n",
        "b = torch.ones((1,n_components))\n",
        "prior_categorical = UniformDistribution({\"a\":a,\n",
        "                                          \"b\":b})\n",
        "\n",
        "# Posterior on latent: Gaussian on R2\n",
        "# (here assumed posterior = assumed prior\n",
        "# but it could have been differnet)\n",
        "mu = torch.zeros((1,latent_dim))\n",
        "std = torch.ones((1,latent_dim))\n",
        "posterior_latent = NormalDistribution({\"mu\":mu,\n",
        "                                        \"std\":std})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e7b2e5c0",
      "metadata": {
        "id": "e7b2e5c0"
      },
      "outputs": [],
      "source": [
        "cv_scVAE = []\n",
        "for fold in tqdm(list(range(len(folds)))):\n",
        "    print(f\"\\nInstantiating scVAE..\")\n",
        "    scVAE = MixtureVAE(\n",
        "            input_dim=input_dim,\n",
        "            hidden_dim=hidden_dim,\n",
        "            n_components=n_components,\n",
        "            n_layers=n_layers,\n",
        "            prior_latent=prior_latent,\n",
        "            prior_input=prior_input,\n",
        "            prior_categorical=prior_categorical,\n",
        "            posterior_latent=posterior_latent\n",
        "        )\n",
        "\n",
        "    train_loader, val_loader = folds[fold]\n",
        "\n",
        "    optimizer = torch.optim.Adam(scVAE.parameters(), lr=1e-4)\n",
        "\n",
        "    EPOCHS = 500\n",
        "    BETA_KL = 1.0\n",
        "    WARMUP_BETA = 200\n",
        "    PATIENCE = 20\n",
        "    TOL = 5e-3\n",
        "\n",
        "    scVAE, losses, parts, clusters, all_betas = training_mvae(\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        scVAE,\n",
        "        optimizer,\n",
        "        epochs=EPOCHS,\n",
        "        beta_kl=BETA_KL,\n",
        "        warmup=WARMUP_BETA,\n",
        "        patience=PATIENCE,\n",
        "        tol=TOL,\n",
        "        show_loss_every=10,\n",
        "        model_type=0,\n",
        "        track_clusters=True,\n",
        "    )\n",
        "\n",
        "    cv_scVAE.append(scVAE)\n",
        "    # plot training and validation losses\n",
        "    plot_loss_components(parts[\"train\"],\n",
        "                         parts[\"val\"],\n",
        "                         all_betas,\n",
        "                         title=\"Loss Breakdown\",\n",
        "                         save_path=f\"./scVAE_{fold}_losses.pdf\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7944b0c4",
      "metadata": {
        "id": "7944b0c4"
      },
      "source": [
        "## **Cross-Validated independent Mixture of Mixtures**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c85ad988",
      "metadata": {
        "id": "c85ad988"
      },
      "outputs": [],
      "source": [
        "from mixture_vae.mvae import ind_MoMVAE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "203fd11d",
      "metadata": {
        "id": "203fd11d"
      },
      "outputs": [],
      "source": [
        "cv_IndMoM = []\n",
        "for fold in tqdm(list(range(len(folds)))):\n",
        "    print(f\"\\nInstantiating IndMoM..\")\n",
        "    IndMoM = ind_MoMVAE(\n",
        "            PARAMS = [\n",
        "            {\"input_dim\": input_dim,\n",
        "            \"hidden_dim\": hidden_dim,\n",
        "            \"n_components\": n_components,\n",
        "            \"n_layers\": n_layers,\n",
        "            \"prior_latent\": prior_latent,\n",
        "            \"prior_input\": prior_input,\n",
        "            \"prior_categorical\": prior_categorical,\n",
        "            \"posterior_latent\": posterior_latent}\n",
        "            for n_components in [2, 3, 5, 9]]\n",
        "        )\n",
        "\n",
        "    train_loader, val_loader = folds[fold]\n",
        "\n",
        "    optimizer = torch.optim.Adam(IndMoM.parameters(), lr=1e-3)\n",
        "\n",
        "    EPOCHS = 500\n",
        "    BETA_KL = 1.0\n",
        "    WARMUP_BETA = 200\n",
        "    PATIENCE = 20\n",
        "    TOL = 5e-3\n",
        "\n",
        "    IndMoM, losses, parts, clusters, all_betas = training_mvae(\n",
        "        train_loader,\n",
        "        val_loader,\n",
        "        IndMoM,\n",
        "        optimizer,\n",
        "        epochs=EPOCHS,\n",
        "        beta_kl=BETA_KL,\n",
        "        warmup=WARMUP_BETA,\n",
        "        patience=PATIENCE,\n",
        "        tol=TOL,\n",
        "        show_loss_every=10,\n",
        "        model_type=1,\n",
        "        track_clusters=True,\n",
        "    )\n",
        "    cv_IndMoM.append(IndMoM)\n",
        "    # plot training and validation losses\n",
        "    plot_loss_components(parts[\"train\"],\n",
        "                         parts[\"val\"],\n",
        "                         all_betas,\n",
        "                         title=\"Loss Breakdown\",\n",
        "                         save_path=f\"./IndMoM_{fold}_losses.pdf\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0accc7a2",
      "metadata": {
        "id": "0accc7a2"
      },
      "source": [
        "## **Cross-Validated Mixture of Mixtures**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "69b4e710",
      "metadata": {
        "id": "69b4e710"
      },
      "outputs": [],
      "source": [
        "from mixture_vae.mvae import MoMixVAE\n",
        "from mixture_vae.training import training_momixvae"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cae7d4b5",
      "metadata": {
        "id": "cae7d4b5"
      },
      "outputs": [],
      "source": [
        "# Prior on cluster repartitions (mixture): Assume balanced\n",
        "# cluster classes = Uniform on [0,1]\n",
        "# currently we assume the same for all levels\n",
        "all_prior_categorical = []\n",
        "for n_components in hierarchy_components:\n",
        "    a = torch.zeros((1,n_components))\n",
        "    b = torch.ones((1,n_components))\n",
        "    prior_categorical = UniformDistribution({\"a\":a,\n",
        "                                            \"b\":b})\n",
        "    all_prior_categorical.append(prior_categorical)\n",
        "\n",
        "# Posterior on latent: Gaussian on R2\n",
        "# (here assumed posterior = assumed prior\n",
        "# but it could have been differnet)\n",
        "# currently we assume the same for all levels\n",
        "all_posterior_latent = []\n",
        "for n_components in hierarchy_components:\n",
        "    mu = torch.zeros((1,latent_dim))\n",
        "    std = torch.ones((1,latent_dim))\n",
        "    posterior_latent = NormalDistribution({\"mu\":mu,\n",
        "                                        \"std\":std})\n",
        "    all_posterior_latent.append(posterior_latent)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b28bc78",
      "metadata": {
        "id": "4b28bc78"
      },
      "outputs": [],
      "source": [
        "cv_MoMix = []\n",
        "for fold in tqdm(list(range(len(folds)))):\n",
        "    print(f\"\\nInstantiating MoMix..\")\n",
        "    MoMix = MoMixVAE(\n",
        "        input_dim=input_dim,\n",
        "        hidden_dim=hidden_dim,\n",
        "        hierarchy_components=hierarchy_components,\n",
        "        n_layers=n_layers,\n",
        "        prior_latent=prior_latent,\n",
        "        prior_input=prior_input,\n",
        "        all_prior_categorical=all_prior_categorical,\n",
        "        all_posterior_latent=all_posterior_latent\n",
        "    )\n",
        "\n",
        "    train_loader, val_loader = folds[fold]\n",
        "\n",
        "    optimizer = torch.optim.Adam(MoMix.parameters(), lr=1e-3)\n",
        "\n",
        "    EPOCHS = 500\n",
        "    BETA_KL = 1.0\n",
        "    WARMUP_BETA = 200\n",
        "    PATIENCE = 20\n",
        "    TOL = 5e-3\n",
        "\n",
        "    MoMix, losses, parts, clusters, all_betas = training_momixvae(\n",
        "        dataloader,\n",
        "        val_dataloader,\n",
        "        model,\n",
        "        optimizer,\n",
        "        epochs=EPOCHS,\n",
        "        beta_kl=BETA_KL,\n",
        "        warmup=WARMUP,\n",
        "        patience=PATIENCE,\n",
        "        tol=TOL,\n",
        "        show_loss_every=10,\n",
        "        track_clusters=True,\n",
        "    )\n",
        "    cv_MoMix.append(MoMix)\n",
        "    # plot training and validation losses\n",
        "    plot_loss_components(parts[\"train\"],\n",
        "                         parts[\"val\"],\n",
        "                         all_betas,\n",
        "                         title=\"Loss Breakdown\",\n",
        "                         save_path=f\"./MoMix_{fold}_losses.pdf\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e4d18c50",
      "metadata": {
        "id": "e4d18c50"
      },
      "source": [
        "# **Figure 1: Generative and Clustering performances**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7885f36c",
      "metadata": {
        "id": "7885f36c"
      },
      "outputs": [],
      "source": [
        "from mixture_vae.figure1 import plot_figure1\n",
        "\n",
        "cv_dico = {\"$\\mathcal{N}$(0,I)\": [cv_scVAE, cv_IndMoM, cv_MoMix]}\n",
        "\n",
        "plot_figure1(cv_dico, test_loader, save_path=\"./Figure1.pdf\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "876e3060",
      "metadata": {
        "id": "876e3060"
      },
      "outputs": [],
      "source": [
        "# from data_pipeline.src.dataloader import build_dataloaders\n",
        "\n",
        "# train_loader, val_loader, test_loader = build_dataloaders(\n",
        "#     shard_dir=\"data_pipeline/data/pbmc_processed/shards\",\n",
        "#     label_maps_path=\"data_pipeline/data/pbmc_processed/label_maps.json\",\n",
        "#     batch_size=512,\n",
        "#     one_hot=True,\n",
        "# )\n",
        "\n",
        "# for i, batch in enumerate(train_loader):\n",
        "#         print(\"Example batch shapes:\")\n",
        "#         print(\"X:\", batch[\"X\"].shape, \"y1:\", batch[\"y1\"].shape, \"y4:\", batch[\"y4\"].shape)\n",
        "#         break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}